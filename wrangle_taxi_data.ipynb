{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "# pip install azureml-opendatasets-runtimeusing\n",
    "from azureml.opendatasets import NycTlcYellow\n",
    "import calendar\n",
    "import numpy.linalg as linalg\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import momepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only need to run this function once\n",
    "def preprocess_lion():\n",
    "    # Download data from https://www.dropbox.com/sh/927yoof5wq6ukeo/AAA--Iyb7UUDhfWIF2fncppba?dl=0\n",
    "    # Put all files into 'data_unwrangled/LION' or change path below\n",
    "    lion_folder = 'data_unwrangled/LION/'\n",
    "    # Load all LION data\n",
    "    links = gpd.read_file(lion_folder+'links.shp')\n",
    "    # Only consider links in Manhattan\n",
    "    links = links[links['LBoro']==1]\n",
    "    # Only consider links that are normal streets\n",
    "    links = links[links['FeatureTyp']=='0']\n",
    "    # Only consider constructed links\n",
    "    links = links[links['Status']=='2']\n",
    "    # Only consider links that have vehicular traffic\n",
    "    links = links[links['TrafDir'] != 'P']\n",
    "    # Ensure *undirected* graph is connected\n",
    "    # Note: We could do this for directed graph but maximum size\n",
    "    # of strongly connected component is 430\n",
    "    graph = momepy.gdf_to_nx(links, approach=\"primal\", directed=False)\n",
    "    for component in nx.connected_components(graph):\n",
    "        if len(component) > 10000:\n",
    "            graph = graph.subgraph(component)\n",
    "    # Use resulting links as infrastructure\n",
    "    _, links = momepy.nx_to_gdf(graph)\n",
    "    links.drop(columns=['node_start', 'node_end'], inplace=True)\n",
    "    # Save both links so we can use it to construct directed graph\n",
    "    links.to_file('data/infrastructure/links.json', driver='GeoJSON')\n",
    "    # Load nodes\n",
    "    nodes = gpd.read_file(lion_folder+'nodes.shp')\n",
    "    # Drop unnecessary columns\n",
    "    nodes.drop(columns=['OBJECTID_1', 'OBJECTID', 'GLOBALID', 'VIntersect'], inplace=True)\n",
    "    # Find nodes that are connected to surviving links\n",
    "    node_IDs = np.union1d(links['NodeIDFrom'], links['NodeIDTo']).astype(int)\n",
    "    # Select nodes that are connected to surviving links\n",
    "    selected_nodes = nodes[nodes['NODEID'].isin(node_IDs)]\n",
    "    # Save to file\n",
    "    selected_nodes.to_file('data/infrastructure/nodes.json', driver='GeoJSON')\n",
    "\n",
    "def load_filter():\n",
    "    filename_filter = 'data_unwrangled/2010 Neighborhood Tabulation Areas (NTAs).geojson'\n",
    "    filter = gpd.read_file(filename_filter)\n",
    "    filter = filter[filter['boro_name'] == 'Manhattan']\n",
    "    return filter\n",
    "\n",
    "# Only need to run this function once for each year\n",
    "def preprocess_collisions(year=2013):\n",
    "    filename_collisions = 'data_unwrangled/Motor_Vehicle_Collisions_-_Crashes.csv'\n",
    "    # Load collisions and drop empty rows\n",
    "    df = pd.read_csv(filename_collisions, low_memory=False).dropna(subset=['LATITUDE', 'LONGITUDE', 'CRASH DATE'])\n",
    "    # Drop empty location data\n",
    "    df = df[df.LONGITUDE != 0] # remove 0,0 coordinates\n",
    "    # Convert date to datetime\n",
    "    df['CRASH DATE'] = pd.to_datetime(df['CRASH DATE'])\n",
    "    # Get year\n",
    "    df['year'] = df['CRASH DATE'].dt.year\n",
    "    # Convert to geodataframe\n",
    "    gdf = gpd.GeoDataFrame(df, crs='epsg:4326', geometry=gpd.points_from_xy(df.LONGITUDE, df.LATITUDE))\n",
    "    # Filter to Manhattan\n",
    "    gdf = gdf.sjoin(load_filter()).drop(columns=['index_right'])\n",
    "    # Subset to year\n",
    "    gdf_year = gdf[gdf['year']==year]\n",
    "    # Save to file\n",
    "    gdf_year.to_file(f'data/infrastructure/collisions_{year}.json', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_taxi(df):\n",
    "    # Make sure rides are longer than one minute\n",
    "    df = df[df['tpepDropoffDateTime'] - df['tpepPickupDateTime'] > np.timedelta64(1, 'm')]\n",
    "    # Make sure rides are shorter than 12 hours\n",
    "    df = df[df['tpepDropoffDateTime'] - df['tpepPickupDateTime'] <= np.timedelta64(12, 'h')]\n",
    "    # Make sure rides are longer than .1 mile\n",
    "    df = df[df['tripDistance'] > 0.1]\n",
    "    # Make sure fare is non-zero \n",
    "    df = df[df['fareAmount'] > 0.0]\n",
    "    # Convert to geopandas\n",
    "    gdf = gpd.GeoDataFrame(df)\n",
    "    # Reset index ID (there are duplicate indices)\n",
    "    gdf.reset_index(inplace=True)\n",
    "    # Create ride ID\n",
    "    gdf['ride_id'] = gdf.index\n",
    "    # Make start time date time type\n",
    "    gdf['start_time'] = pd.to_datetime(gdf['tpepPickupDateTime'])\n",
    "    # Round start time to day\n",
    "    gdf['start_day'] = gdf['start_time'].dt.round('d')\n",
    "    return gdf\n",
    "\n",
    "def filter_location(type, filter, taxi, make_copy=True):\n",
    "    # Create a geometry column from the type coordinates\n",
    "    taxi[f'{type}_geom'] = gpd.points_from_xy(taxi[f'{type}Lon'], taxi[f'{type}Lat'])\n",
    "    taxi.set_geometry(f'{type}_geom', crs='epsg:4326', inplace=True)\n",
    "    taxi = taxi.sjoin(filter)\n",
    "\n",
    "    # Drop the index_right column from sjoin\n",
    "    if 'index_right' in taxi.columns:\n",
    "        taxi.drop(columns=['index_right'], inplace=True)\n",
    "\n",
    "    return taxi\n",
    "\n",
    "def restrict_start_end(taxi, check_ratio=False):        \n",
    "    # Load Manhattan objects\n",
    "    filter_manhattan = load_filter()\n",
    "    # Restrict to rides that start in Manhattan\n",
    "    taxi_start = filter_location('start', filter_manhattan, taxi)\n",
    "    # Restrict to rides that start and end in Manhattan\n",
    "    taxi_start_end = filter_location('end', filter_manhattan, taxi_start)\n",
    "    if check_ratio:\n",
    "        # Check number of rides that start AND end in Manhattan / number of rides that start OR end in Manhattan\n",
    "        taxi_end = filter_location('end', filter_manhattan, taxi)\n",
    "        print(len(taxi_start_end)/(len(taxi_start)+len(taxi_end)-len(taxi_start_end))) # About 85%\n",
    "    return taxi_start_end\n",
    "\n",
    "def get_taxi_data(year, month):\n",
    "    # Get query for first and last day of month in year\n",
    "    month_last_day = calendar.monthrange(year=int(year),month=int(month))[1]\n",
    "    start_date = parser.parse(str(year)+'-'+str(month)+'-01')\n",
    "    end_date = parser.parse(str(year)+'-'+str(month)+'-'+str(month_last_day))\n",
    "    end_date = parser.parse(str(year)+'-'+str(month)+'-02')\n",
    "    print('Loading taxi data...', end=' ')\n",
    "    nyc_tlc = NycTlcYellow(start_date=start_date, end_date=end_date)\n",
    "    taxi_all = nyc_tlc.to_pandas_dataframe()\n",
    "    print('complete!')\n",
    "    print('Preprocessing data...', end=' ')\n",
    "    taxi = preprocess_taxi(taxi_all)\n",
    "    print('complete!')\n",
    "    print('Restricting start and end...', end=' ')\n",
    "    taxi_start_end = restrict_start_end(taxi)\n",
    "    print('complete!')\n",
    "\n",
    "    return taxi_start_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_directed_graph(links):\n",
    "    # Edges from NodeIDFrom to NodeIDTo for one-way \"with\" streets and two-way streets\n",
    "    graph1 = nx.from_pandas_edgelist(\n",
    "        links[np.logical_or(links['TrafDir'] == 'W', links['TrafDir'] == 'T')],\n",
    "        source='NodeIDFrom', target='NodeIDTo', edge_attr=True, create_using=nx.DiGraph()\n",
    "    )\n",
    "    # Edges from NodeIDTo to NodeIDFrom for one-way \"against\" streets and two-way streets\n",
    "    graph2 = nx.from_pandas_edgelist(\n",
    "        links[np.logical_or(links['TrafDir'] == 'A', links['TrafDir'] == 'T')],\n",
    "        source='NodeIDTo', target='NodeIDFrom', edge_attr=True, create_using=nx.DiGraph()\n",
    "    )\n",
    "    return nx.compose(graph1, graph2)\n",
    "\n",
    "def connect_taxi_to_nodes(taxi, type_name, nodes):    \n",
    "    taxi.set_geometry(type_name+'_geom', inplace=True)\n",
    "    taxi.to_crs(nodes.crs, inplace=True)\n",
    "    result = taxi.sjoin_nearest(nodes).drop(columns=['index_right'])\n",
    "    result.rename(columns={'NODEID': type_name+'_NODEID'}, inplace=True)\n",
    "    return result\n",
    "\n",
    "def connect_collisions_to_nodes(collisions, nodes):\n",
    "    collisions.to_crs(nodes.crs, inplace=True)\n",
    "    return collisions.sjoin_nearest(nodes).drop(columns=['index_right'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading taxi data... [Info] read from /var/folders/0n/hqwrwrp96x3g_q8dnhlmvghh0000gn/T/tmp2q4t0ge5/https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2013/puMonth=7/part-00000-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426339-60.c000.snappy.parquet\n",
      "[Info] read from /var/folders/0n/hqwrwrp96x3g_q8dnhlmvghh0000gn/T/tmp2q4t0ge5/https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2013/puMonth=7/part-00008-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426341-60.c000.snappy.parquet\n",
      "[Info] read from /var/folders/0n/hqwrwrp96x3g_q8dnhlmvghh0000gn/T/tmp2q4t0ge5/https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2013/puMonth=7/part-00016-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426328-58.c000.snappy.parquet\n",
      "[Info] read from /var/folders/0n/hqwrwrp96x3g_q8dnhlmvghh0000gn/T/tmp2q4t0ge5/https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2013/puMonth=7/part-00001-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426336-59.c000.snappy.parquet\n",
      "[Info] read from /var/folders/0n/hqwrwrp96x3g_q8dnhlmvghh0000gn/T/tmp2q4t0ge5/https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2013/puMonth=7/part-00009-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426325-58.c000.snappy.parquet\n",
      "[Info] read from /var/folders/0n/hqwrwrp96x3g_q8dnhlmvghh0000gn/T/tmp2q4t0ge5/https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2013/puMonth=7/part-00017-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426323-60.c000.snappy.parquet\n",
      "[Info] read from /var/folders/0n/hqwrwrp96x3g_q8dnhlmvghh0000gn/T/tmp2q4t0ge5/https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2013/puMonth=7/part-00002-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426334-61.c000.snappy.parquet\n",
      "[Info] read from /var/folders/0n/hqwrwrp96x3g_q8dnhlmvghh0000gn/T/tmp2q4t0ge5/https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2013/puMonth=7/part-00010-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426335-59.c000.snappy.parquet\n",
      "[Info] read from /var/folders/0n/hqwrwrp96x3g_q8dnhlmvghh0000gn/T/tmp2q4t0ge5/https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2013/puMonth=7/part-00018-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426329-60.c000.snappy.parquet\n",
      "[Info] read from /var/folders/0n/hqwrwrp96x3g_q8dnhlmvghh0000gn/T/tmp2q4t0ge5/https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2013/puMonth=7/part-00003-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426340-57.c000.snappy.parquet\n",
      "[Info] read from /var/folders/0n/hqwrwrp96x3g_q8dnhlmvghh0000gn/T/tmp2q4t0ge5/https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2013/puMonth=7/part-00011-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426338-59.c000.snappy.parquet\n",
      "[Info] read from /var/folders/0n/hqwrwrp96x3g_q8dnhlmvghh0000gn/T/tmp2q4t0ge5/https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2013/puMonth=7/part-00019-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426333-58.c000.snappy.parquet\n",
      "[Info] read from /var/folders/0n/hqwrwrp96x3g_q8dnhlmvghh0000gn/T/tmp2q4t0ge5/https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2013/puMonth=7/part-00004-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426331-58.c000.snappy.parquet\n",
      "[Info] read from /var/folders/0n/hqwrwrp96x3g_q8dnhlmvghh0000gn/T/tmp2q4t0ge5/https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2013/puMonth=7/part-00012-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426337-59.c000.snappy.parquet\n",
      "[Info] read from /var/folders/0n/hqwrwrp96x3g_q8dnhlmvghh0000gn/T/tmp2q4t0ge5/https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2013/puMonth=7/part-00005-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426324-59.c000.snappy.parquet\n",
      "[Info] read from /var/folders/0n/hqwrwrp96x3g_q8dnhlmvghh0000gn/T/tmp2q4t0ge5/https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2013/puMonth=7/part-00013-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426327-59.c000.snappy.parquet\n",
      "[Info] read from /var/folders/0n/hqwrwrp96x3g_q8dnhlmvghh0000gn/T/tmp2q4t0ge5/https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2013/puMonth=7/part-00006-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426326-58.c000.snappy.parquet\n",
      "[Info] read from /var/folders/0n/hqwrwrp96x3g_q8dnhlmvghh0000gn/T/tmp2q4t0ge5/https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2013/puMonth=7/part-00014-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426330-60.c000.snappy.parquet\n",
      "[Info] read from /var/folders/0n/hqwrwrp96x3g_q8dnhlmvghh0000gn/T/tmp2q4t0ge5/https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2013/puMonth=7/part-00007-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426332-60.c000.snappy.parquet\n",
      "[Info] read from /var/folders/0n/hqwrwrp96x3g_q8dnhlmvghh0000gn/T/tmp2q4t0ge5/https%3A/%2Fazureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2013/puMonth=7/part-00015-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426342-59.c000.snappy.parquet\n",
      "complete!\n",
      "Preprocessing data... complete!\n",
      "Restricting start and end... complete!\n"
     ]
    }
   ],
   "source": [
    "# If you're getting throttled, reset router IP address and computer IP address\n",
    "taxi = get_taxi_data('2013', '7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = gpd.read_file('data/infrastructure/links.json')\n",
    "nodes = gpd.read_file('data/infrastructure/nodes.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = get_directed_graph(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi = connect_taxi_to_nodes(taxi, 'start', nodes)\n",
    "taxi = connect_taxi_to_nodes(taxi, 'end', nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions = gpd.read_file('data/infrastructure/collisions_2013.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions = connect_collisions_to_nodes(collisions, nodes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95ee71ea249aa2e9e4602de52516e559983ad773b5ebbcec62edf843d39d54f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
